# LOGOS V2 Consolidated Validation Framework

## üîç **Comprehensive Testing & Validation Suite**

### **VALIDATION TIER 1: Basic System Health**

#### **V1.1 Import Validation Script**
```python
#!/usr/bin/env python3
"""
Basic import validation for consolidated LOGOS V2
Tests all core consolidated modules for import success
"""
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'LOGOS_V2'))

def test_core_imports():
    """Test consolidated core imports"""
    tests = []
    
    # Test system imports
    try:
        from core.system_imports import *
        tests.append(("‚úÖ System imports", True))
    except Exception as e:
        tests.append((f"‚ùå System imports: {e}", False))
    
    # Test unified classes
    try:
        from core.unified_classes import TrinityVector, UnifiedWorkerConfig
        vector = TrinityVector(0.5, 0.5, 0.5)
        config = UnifiedWorkerConfig()
        tests.append(("‚úÖ Unified classes", True))
    except Exception as e:
        tests.append((f"‚ùå Unified classes: {e}", False))
    
    # Test worker kernel
    try:
        from core.worker_kernel import WorkerKernel
        kernel = WorkerKernel(UnifiedWorkerConfig())
        tests.append(("‚úÖ Worker kernel", True))
    except Exception as e:
        tests.append((f"‚ùå Worker kernel: {e}", False))
        
    # Test Bayesian inference
    try:
        from core.bayesian_inference import BayesianInference
        inference = BayesianInference()
        tests.append(("‚úÖ Bayesian inference", True))
    except Exception as e:
        tests.append((f"‚ùå Bayesian inference: {e}", False))
    
    return tests

if __name__ == "__main__":
    print("üîç LOGOS V2 Core Import Validation")
    print("=" * 40)
    
    results = test_core_imports()
    success_count = sum(1 for _, success in results if success)
    total_count = len(results)
    
    for message, _ in results:
        print(message)
    
    print(f"\nüìä Results: {success_count}/{total_count} tests passed")
    
    if success_count == total_count:
        print("üéâ All core imports successful!")
        sys.exit(0)
    else:
        print("‚ö†Ô∏è  Some core imports failed - check errors above")
        sys.exit(1)
```

#### **V1.2 File Count Validation Script**
```python
#!/usr/bin/env python3
"""
File count and structure validation for LOGOS V2 consolidation
"""
import os
from pathlib import Path

def count_python_files(directory):
    """Count Python files excluding external libraries"""
    python_files = []
    for root, dirs, files in os.walk(directory):
        # Skip external libraries and __pycache__
        if 'external_libraries' in root or '__pycache__' in root:
            continue
        for file in files:
            if file.endswith('.py'):
                python_files.append(os.path.join(root, file))
    return python_files

def count_import_lines(files):
    """Count total import statements across files"""
    import_count = 0
    for file in files:
        try:
            with open(file, 'r', encoding='utf-8') as f:
                content = f.readlines()
                import_count += len([line for line in content if line.strip().startswith(('import ', 'from '))])
        except:
            continue
    return import_count

def validate_consolidation_targets():
    """Validate GPT consolidation targets"""
    logos_v2_path = os.path.join(os.path.dirname(__file__), '..', 'LOGOS_V2')
    
    if not os.path.exists(logos_v2_path):
        print("‚ùå LOGOS_V2 directory not found")
        return False
    
    python_files = count_python_files(logos_v2_path)
    import_lines = count_import_lines(python_files)
    
    print("üìä Consolidation Metrics:")
    print(f"   Python files: {len(python_files)}")
    print(f"   Import lines: {import_lines}")
    print()
    
    # Validate targets
    file_target_met = 190 <= len(python_files) <= 210
    import_target_met = import_lines <= 550
    
    print("üéØ Target Validation:")
    print(f"   File count (190-210): {'‚úÖ' if file_target_met else '‚ùå'} {len(python_files)}")
    print(f"   Import lines (‚â§550): {'‚úÖ' if import_target_met else '‚ùå'} {import_lines}")
    
    if len(python_files) < 190:
        print("‚ö†Ô∏è  File count below target - possible over-consolidation")
    elif len(python_files) > 210:
        print("‚ö†Ô∏è  File count above target - additional consolidation recommended")
    
    return file_target_met and import_target_met

if __name__ == "__main__":
    print("üîç LOGOS V2 Consolidation Validation")
    print("=" * 40)
    
    success = validate_consolidation_targets()
    
    if success:
        print("\nüéâ Consolidation targets achieved!")
    else:
        print("\n‚ö†Ô∏è  Consolidation targets not fully met")
```

### **VALIDATION TIER 2: Functional Testing**

#### **V2.1 Trinity Vector Validation**
```python
#!/usr/bin/env python3
"""
Trinity Vector consolidated functionality validation
"""
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'LOGOS_V2'))

from core.unified_classes import TrinityVector

def test_trinity_vector():
    """Test Trinity Vector consolidated functionality"""
    print("üîç Testing Trinity Vector...")
    
    # Test 1: Basic construction
    try:
        vector = TrinityVector(0.6, 0.8, 0.0)
        print(f"‚úÖ Vector creation: E={vector.existence:.3f}, G={vector.goodness:.3f}, T={vector.truth:.3f}")
    except Exception as e:
        print(f"‚ùå Vector creation failed: {e}")
        return False
    
    # Test 2: Magnitude calculation
    try:
        magnitude = vector.magnitude()
        print(f"‚úÖ Magnitude calculation: {magnitude:.3f}")
        
        # Should be normalized to 1.0 after __post_init__
        expected_magnitude = 1.0
        if abs(magnitude - expected_magnitude) < 0.001:
            print("‚úÖ Auto-normalization working")
        else:
            print(f"‚ö†Ô∏è  Auto-normalization issue: expected ~1.0, got {magnitude:.3f}")
    except Exception as e:
        print(f"‚ùå Magnitude calculation failed: {e}")
        return False
    
    # Test 3: Trinity product
    try:
        product = vector.trinity_product()
        print(f"‚úÖ Trinity product: {product:.6f}")
    except Exception as e:
        print(f"‚ùå Trinity product failed: {e}")
        return False
    
    return True

if __name__ == "__main__":
    print("üîç Trinity Vector Validation")
    print("=" * 30)
    
    success = test_trinity_vector()
    
    if success:
        print("\nüéâ Trinity Vector validation successful!")
    else:
        print("\n‚ùå Trinity Vector validation failed!")
```

#### **V2.2 Worker Kernel Validation**
```python
#!/usr/bin/env python3
"""
Worker Kernel consolidated functionality validation
"""
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'LOGOS_V2'))

from core.worker_kernel import WorkerKernel
from core.unified_classes import UnifiedWorkerConfig

def test_worker_kernel():
    """Test Worker Kernel functionality"""
    print("üîç Testing Worker Kernel...")
    
    # Test 1: Kernel creation
    try:
        config = UnifiedWorkerConfig(max_workers=2, timeout=10.0)
        kernel = WorkerKernel(config)
        print("‚úÖ Worker kernel creation successful")
    except Exception as e:
        print(f"‚ùå Worker kernel creation failed: {e}")
        return False
    
    # Test 2: Worker management
    try:
        # Start workers up to limit
        result1 = kernel.start_worker("worker1", "task1")
        result2 = kernel.start_worker("worker2", "task2") 
        result3 = kernel.start_worker("worker3", "task3")  # Should queue
        
        print(f"‚úÖ Worker start results: {result1}, {result2}, {result3}")
        print(f"‚úÖ Active workers: {len(kernel.active_workers)}")
        print(f"‚úÖ Queued workers: {len(kernel.worker_queue)}")
        
        # Test status retrieval
        status = kernel.get_worker_status("worker1")
        all_status = kernel.get_all_workers_status()
        
        print(f"‚úÖ Worker status retrieval: {len(all_status)} active workers")
        
        # Test worker stopping
        stop_result = kernel.stop_worker("worker1")
        print(f"‚úÖ Worker stop result: {stop_result}")
        print(f"‚úÖ Active workers after stop: {len(kernel.active_workers)}")
        
    except Exception as e:
        print(f"‚ùå Worker management failed: {e}")
        return False
    
    return True

if __name__ == "__main__":
    print("üîç Worker Kernel Validation")
    print("=" * 30)
    
    success = test_worker_kernel()
    
    if success:
        print("\nüéâ Worker Kernel validation successful!")
    else:
        print("\n‚ùå Worker Kernel validation failed!")
```

#### **V2.3 Bayesian Inference Validation**
```python
#!/usr/bin/env python3
"""
Bayesian Inference consolidated functionality validation
"""
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'LOGOS_V2'))

from core.bayesian_inference import BayesianInference

def test_bayesian_inference():
    """Test Bayesian Inference functionality"""
    print("üîç Testing Bayesian Inference...")
    
    # Test 1: Inference creation
    try:
        inference = BayesianInference()
        print("‚úÖ Bayesian inference creation successful")
    except Exception as e:
        print(f"‚ùå Bayesian inference creation failed: {e}")
        return False
    
    # Test 2: Posterior calculation
    try:
        prior = 0.3
        likelihood = 0.8
        evidence = 0.5
        
        posterior = inference.calculate_posterior(prior, likelihood, evidence)
        expected = (prior * likelihood) / evidence
        
        print(f"‚úÖ Posterior calculation: {posterior:.3f} (expected: {expected:.3f})")
        
        if abs(posterior - expected) < 0.001:
            print("‚úÖ Posterior calculation accurate")
        else:
            print(f"‚ö†Ô∏è  Posterior calculation discrepancy")
            
    except Exception as e:
        print(f"‚ùå Posterior calculation failed: {e}")
        return False
    
    # Test 3: Batch belief update
    try:
        hypotheses = {"H1": 0.4, "H2": 0.6}
        evidence_batch = [("H1", 0.7), ("H2", 0.3)]
        
        updated = inference.update_belief_batch(hypotheses, evidence_batch)
        print(f"‚úÖ Batch update: {updated}")
        
        # Test most probable
        most_prob_hyp, most_prob_val = inference.get_most_probable(updated)
        print(f"‚úÖ Most probable: {most_prob_hyp} ({most_prob_val:.3f})")
        
    except Exception as e:
        print(f"‚ùå Batch processing failed: {e}")
        return False
    
    return True

if __name__ == "__main__":
    print("üîç Bayesian Inference Validation")
    print("=" * 35)
    
    success = test_bayesian_inference()
    
    if success:
        print("\nüéâ Bayesian Inference validation successful!")
    else:
        print("\n‚ùå Bayesian Inference validation failed!")
```

### **VALIDATION TIER 3: Integration Testing**

#### **V3.1 Cross-Module Integration Test**
```python
#!/usr/bin/env python3
"""
Cross-module integration testing for consolidated LOGOS V2
"""
import sys
import os
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'LOGOS_V2'))

def test_integrated_workflow():
    """Test integrated workflow using consolidated modules"""
    print("üîç Testing Integrated Workflow...")
    
    try:
        # Import all consolidated modules
        from core.unified_classes import TrinityVector, UnifiedWorkerConfig
        from core.worker_kernel import WorkerKernel
        from core.bayesian_inference import BayesianInference
        
        print("‚úÖ All modules imported successfully")
        
        # Create integrated components
        vector = TrinityVector(0.7, 0.2, 0.1)
        config = UnifiedWorkerConfig(max_workers=3)
        kernel = WorkerKernel(config)
        inference = BayesianInference()
        
        print("‚úÖ All components created successfully")
        
        # Test integrated operation
        # 1. Start a worker with Trinity vector task
        task = {
            'vector': vector,
            'operation': 'trinity_analysis'
        }
        
        worker_started = kernel.start_worker("trinity_worker", task)
        print(f"‚úÖ Worker started with Trinity task: {worker_started}")
        
        # 2. Use Bayesian inference on worker results
        hypotheses = {
            'vector_valid': 0.8,
            'vector_invalid': 0.2
        }
        
        # Simulate evidence based on vector properties
        evidence = [
            ('vector_valid', vector.magnitude()),
            ('vector_invalid', 1.0 - vector.magnitude())
        ]
        
        updated_beliefs = inference.update_belief_batch(hypotheses, evidence)
        most_probable = inference.get_most_probable(updated_beliefs)
        
        print(f"‚úÖ Integrated Bayesian analysis: {most_probable}")
        
        # 3. Clean up
        kernel.stop_worker("trinity_worker")
        print("‚úÖ Workflow cleanup successful")
        
        return True
        
    except Exception as e:
        print(f"‚ùå Integrated workflow failed: {e}")
        return False

if __name__ == "__main__":
    print("üîç Cross-Module Integration Test")
    print("=" * 40)
    
    success = test_integrated_workflow()
    
    if success:
        print("\nüéâ Integration test successful!")
    else:
        print("\n‚ùå Integration test failed!")
```

### **VALIDATION EXECUTION SUITE**

#### **Master Validation Runner**
```powershell
# Run_All_Validations.ps1
# Master validation suite for LOGOS V2 consolidation

Write-Host "üîç LOGOS V2 Consolidation - Master Validation Suite" -ForegroundColor Green
Write-Host "===================================================" -ForegroundColor Green

$validationPath = "V1_to_V2_Migration"
$results = @()

# Tier 1 Validations
Write-Host "`nüìä TIER 1: Basic System Health" -ForegroundColor Cyan

Write-Host "Running import validation..."
try {
    $output = & python "$validationPath/V1.1_Import_Validation.py"
    $success = $LASTEXITCODE -eq 0
    $results += @{Test="Import Validation"; Success=$success; Output=$output}
    if ($success) { Write-Host "‚úÖ PASSED" -ForegroundColor Green } else { Write-Host "‚ùå FAILED" -ForegroundColor Red }
} catch {
    $results += @{Test="Import Validation"; Success=$false; Output="Exception: $_"}
    Write-Host "‚ùå FAILED (Exception)" -ForegroundColor Red
}

Write-Host "Running file count validation..."
try {
    $output = & python "$validationPath/V1.2_File_Count_Validation.py"
    $success = $LASTEXITCODE -eq 0
    $results += @{Test="File Count Validation"; Success=$success; Output=$output}
    if ($success) { Write-Host "‚úÖ PASSED" -ForegroundColor Green } else { Write-Host "‚ùå FAILED" -ForegroundColor Red }
} catch {
    $results += @{Test="File Count Validation"; Success=$false; Output="Exception: $_"}
    Write-Host "‚ùå FAILED (Exception)" -ForegroundColor Red
}

# Tier 2 Validations
Write-Host "`nüîß TIER 2: Functional Testing" -ForegroundColor Cyan

$functionalTests = @(
    @{Name="Trinity Vector"; Script="V2.1_Trinity_Vector_Validation.py"},
    @{Name="Worker Kernel"; Script="V2.2_Worker_Kernel_Validation.py"},
    @{Name="Bayesian Inference"; Script="V2.3_Bayesian_Inference_Validation.py"}
)

foreach ($test in $functionalTests) {
    Write-Host "Running $($test.Name) validation..."
    try {
        $output = & python "$validationPath/$($test.Script)"
        $success = $LASTEXITCODE -eq 0
        $results += @{Test=$test.Name; Success=$success; Output=$output}
        if ($success) { Write-Host "‚úÖ PASSED" -ForegroundColor Green } else { Write-Host "‚ùå FAILED" -ForegroundColor Red }
    } catch {
        $results += @{Test=$test.Name; Success=$false; Output="Exception: $_"}
        Write-Host "‚ùå FAILED (Exception)" -ForegroundColor Red
    }
}

# Tier 3 Validations
Write-Host "`nüîó TIER 3: Integration Testing" -ForegroundColor Cyan

Write-Host "Running cross-module integration test..."
try {
    $output = & python "$validationPath/V3.1_Cross_Module_Integration.py"
    $success = $LASTEXITCODE -eq 0
    $results += @{Test="Cross-Module Integration"; Success=$success; Output=$output}
    if ($success) { Write-Host "‚úÖ PASSED" -ForegroundColor Green } else { Write-Host "‚ùå FAILED" -ForegroundColor Red }
} catch {
    $results += @{Test="Cross-Module Integration"; Success=$false; Output="Exception: $_"}
    Write-Host "‚ùå FAILED (Exception)" -ForegroundColor Red
}

# Summary
Write-Host "`nüìà VALIDATION SUMMARY" -ForegroundColor Yellow
Write-Host "=====================" -ForegroundColor Yellow

$passedTests = ($results | Where-Object { $_.Success }).Count
$totalTests = $results.Count

Write-Host "Tests Passed: $passedTests / $totalTests"

$results | ForEach-Object {
    $status = if ($_.Success) { "‚úÖ PASS" } else { "‚ùå FAIL" }
    Write-Host "  $status - $($_.Test)"
}

if ($passedTests -eq $totalTests) {
    Write-Host "`nüéâ ALL VALIDATIONS PASSED! Consolidation successful." -ForegroundColor Green
} else {
    Write-Host "`n‚ö†Ô∏è  SOME VALIDATIONS FAILED! Review output above." -ForegroundColor Red
}
```

---

## **üéØ VALIDATION FRAMEWORK SUMMARY**

### **Three-Tier Validation:**
- **Tier 1**: Basic imports and file structure validation
- **Tier 2**: Functional testing of consolidated modules  
- **Tier 3**: Cross-module integration testing

### **Automated Execution:**
```powershell
./Run_All_Validations.ps1
```

**Status**: üü¢ **VALIDATION FRAMEWORK COMPLETE** - Comprehensive testing suite for GPT consolidation validation with automated reporting.